{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gru_ode_bayes\n",
    "import gru_ode_bayes.data_utils as data_utils\n",
    "import time\n",
    "import tqdm\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gru_ode_bayes import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gruode(simulation_name,params_dict,device, train_idx, val_idx, test_idx, epoch_max=40):\n",
    "    csv_file_path = params_dict[\"csv_file_path\"]\n",
    "    csv_file_cov = params_dict[\"csv_file_cov\"]\n",
    "    csv_file_tags = params_dict[\"csv_file_tags\"]\n",
    "\n",
    "    N = pd.read_csv(csv_file_path)[\"ID\"].nunique()\n",
    "    \n",
    "    if params_dict[\"lambda\"]==0:\n",
    "        validation = True\n",
    "        val_options = {\"T_val\": params_dict[\"T_val\"], \"max_val_samples\": params_dict[\"max_val_samples\"]}\n",
    "    else:\n",
    "        validation = False\n",
    "        val_options = None\n",
    "\n",
    "    if params_dict[\"lambda\"]==0:\n",
    "        logger = Logger(f'./Logs/{simulation_name}')\n",
    "    else:\n",
    "        logger = Logger(f'./Logs/{simulation_name}')\n",
    "\n",
    "\n",
    "    data_train = data_utils.ODE_Dataset(csv_file=csv_file_path,label_file=csv_file_tags, cov_file= csv_file_cov, idx=train_idx)\n",
    "    data_val   = data_utils.ODE_Dataset(csv_file=csv_file_path,label_file=csv_file_tags,\n",
    "                                        cov_file= csv_file_cov, idx=val_idx, validation = validation,\n",
    "                                        val_options = val_options)\n",
    "    data_test   = data_utils.ODE_Dataset(csv_file=csv_file_path,label_file=csv_file_tags,\n",
    "                                        cov_file= csv_file_cov, idx=test_idx, validation = validation,\n",
    "                                        val_options = val_options)\n",
    "\n",
    "    dl   = DataLoader(dataset=data_train, collate_fn=data_utils.custom_collate_fn, shuffle=True, batch_size=500,num_workers=2)\n",
    "    dl_val = DataLoader(dataset=data_val, collate_fn=data_utils.custom_collate_fn, shuffle=True, batch_size=len(val_idx))\n",
    "    dl_test = DataLoader(dataset=data_test, collate_fn=data_utils.custom_collate_fn, shuffle=True, batch_size=len(test_idx))\n",
    "\n",
    "\n",
    "    params_dict[\"input_size\"]=data_train.variable_num\n",
    "    params_dict[\"cov_size\"] = data_train.cov_dim\n",
    "\n",
    "    train_folder = \"./../trained_models/\"\n",
    "    if not os.path.exists(train_folder):\n",
    "        os.makedirs(train_folder)\n",
    "    np.save(train_folder + f\"{simulation_name}_params.npy\", params_dict)\n",
    "\n",
    "    nnfwobj = gru_ode_bayes.NNFOwithBayesianJumps(input_size = params_dict[\"input_size\"], hidden_size = params_dict[\"hidden_size\"],\n",
    "                                            p_hidden = params_dict[\"p_hidden\"], prep_hidden = params_dict[\"prep_hidden\"],\n",
    "                                            logvar = params_dict[\"logvar\"], mixing = params_dict[\"mixing\"],\n",
    "                                            classification_hidden=params_dict[\"classification_hidden\"],\n",
    "                                            cov_size = params_dict[\"cov_size\"], cov_hidden = params_dict[\"cov_hidden\"],\n",
    "                                            dropout_rate = params_dict[\"dropout_rate\"],full_gru_ode= params_dict[\"full_gru_ode\"], impute = params_dict[\"impute\"])\n",
    "    nnfwobj.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(nnfwobj.parameters(), lr=params_dict[\"lr\"], weight_decay= params_dict[\"weight_decay\"])\n",
    "    class_criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    print(\"Start Training\")\n",
    "    val_metric_prev = -1000\n",
    "    for epoch in range(epoch_max):\n",
    "        nnfwobj.train()\n",
    "        total_train_loss = 0\n",
    "        auc_total_train  = 0\n",
    "        tot_loglik_loss = 0\n",
    "        for i, b in enumerate(tqdm.tqdm(dl)):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            times    = b[\"times\"]\n",
    "            time_ptr = b[\"time_ptr\"]\n",
    "            X        = b[\"X\"].to(device)\n",
    "            M        = b[\"M\"].to(device)\n",
    "            obs_idx  = b[\"obs_idx\"]\n",
    "            cov      = b[\"cov\"].to(device)\n",
    "            labels = b[\"y\"].to(device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            h0 = 0# torch.zeros(labels.shape[0], params_dict[\"hidden_size\"]).to(device)\n",
    "            hT, loss, class_pred, mse_loss  = nnfwobj(times, time_ptr, X, M, obs_idx, delta_t=params_dict[\"delta_t\"], T=params_dict[\"T\"], cov = cov)\n",
    "\n",
    "            total_loss = (loss + params_dict[\"lambda\"]*class_criterion(class_pred, labels))/batch_size\n",
    "            total_train_loss += total_loss\n",
    "            tot_loglik_loss +=mse_loss\n",
    "            try:\n",
    "                auc_total_train += roc_auc_score(labels.detach().cpu(),torch.sigmoid(class_pred).detach().cpu())\n",
    "            except ValueError:\n",
    "                if params_dict[\"verbose\"]>=3:\n",
    "                    print(\"Single CLASS ! AUC is erroneous\")\n",
    "                pass\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    " \n",
    "        \n",
    "        info = { 'training_loss' : total_train_loss.detach().cpu().numpy()/(i+1), 'AUC_training' : auc_total_train/(i+1), \"loglik_loss\" :tot_loglik_loss.detach().cpu().numpy()}\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, epoch)\n",
    "        print(f\"NegLogLik Loss train : {tot_loglik_loss.detach().cpu().numpy()}\")\n",
    "\n",
    "        data_utils.adjust_learning_rate(optimizer,epoch,params_dict[\"lr\"])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            nnfwobj.eval()\n",
    "            total_loss_val = 0\n",
    "            auc_total_val = 0\n",
    "            loss_val = 0\n",
    "            mse_val  = 0\n",
    "            corr_val = 0\n",
    "            num_obs = 0\n",
    "            for i, b in enumerate(dl_val):\n",
    "                times    = b[\"times\"]\n",
    "                time_ptr = b[\"time_ptr\"]\n",
    "                X        = b[\"X\"].to(device)\n",
    "                M        = b[\"M\"].to(device)\n",
    "                obs_idx  = b[\"obs_idx\"]\n",
    "                cov      = b[\"cov\"].to(device)\n",
    "                labels   = b[\"y\"].to(device)\n",
    "                batch_size = labels.size(0)\n",
    "\n",
    "                if b[\"X_val\"] is not None:\n",
    "                    X_val     = b[\"X_val\"].to(device)\n",
    "                    M_val     = b[\"M_val\"].to(device)\n",
    "                    times_val = b[\"times_val\"]\n",
    "                    times_idx = b[\"index_val\"]\n",
    "\n",
    "                h0 = 0 #torch.zeros(labels.shape[0], params_dict[\"hidden_size\"]).to(device)\n",
    "                hT, loss, class_pred, t_vec, p_vec, h_vec, _, _  = nnfwobj(times, time_ptr, X, M, obs_idx, delta_t=params_dict[\"delta_t\"], T=params_dict[\"T\"], cov=cov, return_path=True)\n",
    "                total_loss = (loss + params_dict[\"lambda\"]*class_criterion(class_pred, labels))/batch_size\n",
    "\n",
    "                try:\n",
    "                    auc_val=roc_auc_score(labels.cpu(),torch.sigmoid(class_pred).cpu())\n",
    "                except ValueError:\n",
    "                    auc_val = 0.5\n",
    "                    if params_dict[\"verbose\"]>=3:\n",
    "                        print(\"Only one class : AUC is erroneous\")\n",
    "                    pass\n",
    "\n",
    "                if params_dict[\"lambda\"]==0:\n",
    "                    t_vec = np.around(t_vec,str(params_dict[\"delta_t\"])[::-1].find('.')).astype(np.float32) #Round floating points error in the time vector.\n",
    "                    p_val = data_utils.extract_from_path(t_vec,p_vec,times_val,times_idx)\n",
    "                    m, v = torch.chunk(p_val,2,dim=1)\n",
    "                    last_loss = (data_utils.log_lik_gaussian(X_val,m,v)*M_val).sum()\n",
    "                    mse_loss = (torch.pow(X_val-m,2)*M_val).sum()\n",
    "                    corr_val_loss = data_utils.compute_corr(X_val, m, M_val)\n",
    "\n",
    "                    loss_val += last_loss.cpu().numpy()\n",
    "                    num_obs += M_val.sum().cpu().numpy()\n",
    "                    mse_val += mse_loss.cpu().numpy()\n",
    "                    corr_val += corr_val_loss.cpu().numpy()\n",
    "                else:\n",
    "                    num_obs=1\n",
    "\n",
    "                total_loss_val += total_loss.cpu().detach().numpy()\n",
    "                auc_total_val += auc_val\n",
    "\n",
    "            loss_val /= num_obs\n",
    "            mse_val /=  num_obs\n",
    "            info = { 'validation_loss' : total_loss_val/(i+1), 'AUC_validation' : auc_total_val/(i+1),\n",
    "                     'loglik_loss' : loss_val, 'validation_mse' : mse_val, 'correlation_mean' : np.nanmean(corr_val),\n",
    "                    'correlation_max': np.nanmax(corr_val), 'correlation_min': np.nanmin(corr_val)}\n",
    "            for tag, value in info.items():\n",
    "                logger.scalar_summary(tag, value, epoch)\n",
    "\n",
    "            if params_dict[\"lambda\"]==0:\n",
    "                val_metric = - loss_val\n",
    "            else:\n",
    "                val_metric = auc_total_val/(i+1)\n",
    "\n",
    "            if val_metric > val_metric_prev:\n",
    "                print(f\"New highest validation metric reached ! : {val_metric}\")\n",
    "                print(\"Saving Model\")\n",
    "                torch.save(nnfwobj.state_dict(),f\"./../trained_models/{simulation_name}_MAX.pt\")\n",
    "                val_metric_prev = val_metric\n",
    "                test_loglik, test_auc, test_mse = test_evaluation(nnfwobj, params_dict, class_criterion, device, dl_test)\n",
    "                print(f\"Test loglik loss at epoch {epoch} : {test_loglik}\")\n",
    "                print(f\"Test AUC loss at epoch {epoch} : {test_auc}\")\n",
    "                print(f\"Test MSE loss at epoch{epoch} : {test_mse}\")\n",
    "            else:\n",
    "                if epoch % 10:\n",
    "                    torch.save(nnfwobj.state_dict(),f\"./../trained_models/{simulation_name}.pt\")\n",
    "\n",
    "        print(f\"Total validation loss at epoch {epoch}: {total_loss_val/(i+1)}\")\n",
    "        print(f\"Validation AUC at epoch {epoch}: {auc_total_val/(i+1)}\")\n",
    "        print(f\"Validation loss (loglik) at epoch {epoch}: {loss_val:.5f}. MSE : {mse_val:.5f}. Correlation : {np.nanmean(corr_val):.5f}. Num obs = {num_obs}\")\n",
    "\n",
    "    print(f\"Finished training GRU-ODE for Climate. Saved in ./../trained_models/{simulation_name}\")\n",
    "\n",
    "    return(info, val_metric_prev, test_loglik, test_auc, test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(model, params_dict, class_criterion, device, dl_test):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss_test = 0\n",
    "        auc_total_test = 0\n",
    "        loss_test = 0\n",
    "        mse_test  = 0\n",
    "        corr_test = 0\n",
    "        num_obs = 0\n",
    "        for i, b in enumerate(dl_test):\n",
    "            times    = b[\"times\"]\n",
    "            time_ptr = b[\"time_ptr\"]\n",
    "            X        = b[\"X\"].to(device)\n",
    "            M        = b[\"M\"].to(device)\n",
    "            obs_idx  = b[\"obs_idx\"]\n",
    "            cov      = b[\"cov\"].to(device)\n",
    "            labels   = b[\"y\"].to(device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            if b[\"X_val\"] is not None:\n",
    "                X_val     = b[\"X_val\"].to(device)\n",
    "                M_val     = b[\"M_val\"].to(device)\n",
    "                times_val = b[\"times_val\"]\n",
    "                times_idx = b[\"index_val\"]\n",
    "\n",
    "            h0 = 0 #torch.zeros(labels.shape[0], params_dict[\"hidden_size\"]).to(device)\n",
    "            hT, loss, class_pred, t_vec, p_vec, h_vec, _ , _ = model(times, time_ptr, X, M, obs_idx, delta_t=params_dict[\"delta_t\"], T=params_dict[\"T\"], cov=cov, return_path=True)\n",
    "            total_loss = (loss + params_dict[\"lambda\"]*class_criterion(class_pred, labels))/batch_size\n",
    "\n",
    "            try:\n",
    "                auc_test=roc_auc_score(labels.cpu(),torch.sigmoid(class_pred).cpu())\n",
    "            except ValueError:\n",
    "                if params_dict[\"verbose\"]>=3:\n",
    "                    print(\"Only one class. AUC is wrong\")\n",
    "                auc_test = 0\n",
    "                pass\n",
    "\n",
    "            if params_dict[\"lambda\"]==0:\n",
    "                t_vec = np.around(t_vec,str(params_dict[\"delta_t\"])[::-1].find('.')).astype(np.float32) #Round floating points error in the time vector.\n",
    "                p_val = data_utils.extract_from_path(t_vec,p_vec,times_val,times_idx)\n",
    "                m, v = torch.chunk(p_val,2,dim=1)\n",
    "                last_loss = (data_utils.log_lik_gaussian(X_val,m,v)*M_val).sum()\n",
    "                mse_loss = (torch.pow(X_val-m,2)*M_val).sum()\n",
    "                corr_test_loss = data_utils.compute_corr(X_val, m, M_val)\n",
    "\n",
    "                loss_test += last_loss.cpu().numpy()\n",
    "                num_obs += M_val.sum().cpu().numpy()\n",
    "                mse_test += mse_loss.cpu().numpy()\n",
    "                corr_test += corr_test_loss.cpu().numpy()\n",
    "            else:\n",
    "                num_obs=1\n",
    "\n",
    "            total_loss_test += total_loss.cpu().detach().numpy()\n",
    "            auc_total_test += auc_test\n",
    "\n",
    "        loss_test /= num_obs\n",
    "        mse_test /=  num_obs\n",
    "        auc_total_test /= (i+1)\n",
    "\n",
    "        return(loss_test, auc_total_test, mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45984.8046875\n",
      "New highest validation metric reached ! : -1.1155592217502823\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 0 : 1.1484963758936468\n",
      "Test AUC loss at epoch 0 : 0.0\n",
      "Test MSE loss at epoch0 : 0.4470938556599167\n",
      "Total validation loss at epoch 0: 855.5906982421875\n",
      "Validation AUC at epoch 0: 0.5\n",
      "Validation loss (loglik) at epoch 0: 1.11556. MSE : 0.38579. Correlation : 0.05126. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45811.19921875\n",
      "New highest validation metric reached ! : -1.113166441400367\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 1 : 1.1461261533341318\n",
      "Test AUC loss at epoch 1 : 0.0\n",
      "Test MSE loss at epoch1 : 0.4469131973554503\n",
      "Total validation loss at epoch 1: 850.889892578125\n",
      "Validation AUC at epoch 1: 0.5\n",
      "Validation loss (loglik) at epoch 1: 1.11317. MSE : 0.38683. Correlation : 0.02345. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45632.68359375\n",
      "New highest validation metric reached ! : -1.111161657126553\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 2 : 1.144041529241598\n",
      "Test AUC loss at epoch 2 : 0.0\n",
      "Test MSE loss at epoch2 : 0.44736462719035597\n",
      "Total validation loss at epoch 2: 846.6905517578125\n",
      "Validation AUC at epoch 2: 0.5\n",
      "Validation loss (loglik) at epoch 2: 1.11116. MSE : 0.38881. Correlation : 0.01809. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45487.3515625\n",
      "New highest validation metric reached ! : -1.1093977962631778\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 3 : 1.1422990043208283\n",
      "Test AUC loss at epoch 3 : 0.0\n",
      "Test MSE loss at epoch3 : 0.4484667508107311\n",
      "Total validation loss at epoch 3: 842.750244140625\n",
      "Validation AUC at epoch 3: 0.5\n",
      "Validation loss (loglik) at epoch 3: 1.10940. MSE : 0.39143. Correlation : 0.01599. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45452.58203125\n",
      "New highest validation metric reached ! : -1.1078276117163968\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 4 : 1.14082847451264\n",
      "Test AUC loss at epoch 4 : 0.0\n",
      "Test MSE loss at epoch4 : 0.45003772231767764\n",
      "Total validation loss at epoch 4: 839.1463623046875\n",
      "Validation AUC at epoch 4: 0.5\n",
      "Validation loss (loglik) at epoch 4: 1.10783. MSE : 0.39448. Correlation : 0.01465. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45315.66015625\n",
      "New highest validation metric reached ! : -1.1062731455607586\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 5 : 1.139468786851415\n",
      "Test AUC loss at epoch 5 : 0.0\n",
      "Test MSE loss at epoch5 : 0.4518768022645195\n",
      "Total validation loss at epoch 5: 835.82275390625\n",
      "Validation AUC at epoch 5: 0.5\n",
      "Validation loss (loglik) at epoch 5: 1.10627. MSE : 0.39774. Correlation : 0.01423. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45168.03515625\n",
      "New highest validation metric reached ! : -1.1047032367752259\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 6 : 1.1381108985756927\n",
      "Test AUC loss at epoch 6 : 0.0\n",
      "Test MSE loss at epoch6 : 0.45370677732071785\n",
      "Total validation loss at epoch 6: 832.6416625976562\n",
      "Validation AUC at epoch 6: 0.5\n",
      "Validation loss (loglik) at epoch 6: 1.10470. MSE : 0.40100. Correlation : 0.01462. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45030.61328125\n",
      "New highest validation metric reached ! : -1.1031381997717433\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 7 : 1.1367386871913694\n",
      "Test AUC loss at epoch 7 : 0.0\n",
      "Test MSE loss at epoch7 : 0.45557381971827093\n",
      "Total validation loss at epoch 7: 829.6011352539062\n",
      "Validation AUC at epoch 7: 0.5\n",
      "Validation loss (loglik) at epoch 7: 1.10314. MSE : 0.40430. Correlation : 0.01537. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 45050.57421875\n",
      "New highest validation metric reached ! : -1.101597521678511\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loglik loss at epoch 8 : 1.1353665477824662\n",
      "Test AUC loss at epoch 8 : 0.0\n",
      "Test MSE loss at epoch8 : 0.45741642646069797\n",
      "Total validation loss at epoch 8: 826.6307983398438\n",
      "Validation AUC at epoch 8: 0.5\n",
      "Validation loss (loglik) at epoch 8: 1.10160. MSE : 0.40760. Correlation : 0.01641. Num obs = 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLik Loss train : 44930.9140625\n",
      "New highest validation metric reached ! : -1.1002436258706703\n",
      "Saving Model\n",
      "Test loglik loss at epoch 9 : 1.1339793655107606\n",
      "Test AUC loss at epoch 9 : 0.0\n",
      "Test MSE loss at epoch9 : 0.4593003470942659\n",
      "Total validation loss at epoch 9: 823.5925903320312\n",
      "Validation AUC at epoch 9: 0.5\n",
      "Validation loss (loglik) at epoch 9: 1.10024. MSE : 0.41112. Correlation : 0.01733. Num obs = 83.0\n",
      "Finished training GRU-ODE for Climate. Saved in ./../trained_models/small_climate\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ ==\"__main__\":\n",
    "\n",
    "    simulation_name=\"small_climate\"\n",
    "    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    train_idx = np.load(\"../../gru_ode_bayes/datasets/me/datasets/me_0/train_idx.npy\",allow_pickle=True)\n",
    "    val_idx = np.load(\"../../gru_ode_bayes/datasets/me/datasets/me_0/val_idx.npy\",allow_pickle=True)\n",
    "    test_idx = np.load(\"../../gru_ode_bayes/datasets/me/datasets/me_0/test_idx.npy\",allow_pickle=True)\n",
    "\n",
    "    #Model parameters.\n",
    "    params_dict=dict()\n",
    "\n",
    "    params_dict[\"csv_file_path\"] = \"../../gru_ode_bayes/datasets/Climate/small_chunked_sporadic.csv\" \n",
    "    params_dict[\"csv_file_tags\"] = None\n",
    "    params_dict[\"csv_file_cov\"]  = None\n",
    "\n",
    "    params_dict[\"hidden_size\"] = 50\n",
    "    params_dict[\"p_hidden\"] = 25\n",
    "    params_dict[\"prep_hidden\"] = 10\n",
    "    params_dict[\"logvar\"] = True\n",
    "    params_dict[\"mixing\"] = 1e-4 #Weighting between KL loss and MSE loss.\n",
    "    params_dict[\"delta_t\"]=0.1\n",
    "    params_dict[\"T\"]=200\n",
    "    params_dict[\"lambda\"] = 0 #Weighting between classification and MSE loss.\n",
    "\n",
    "    params_dict[\"classification_hidden\"] = 2\n",
    "    params_dict[\"cov_hidden\"] = 50\n",
    "    params_dict[\"weight_decay\"] = 0.0001\n",
    "    params_dict[\"dropout_rate\"] = 0.2\n",
    "    params_dict[\"lr\"]=0.001\n",
    "    params_dict[\"full_gru_ode\"] = True\n",
    "    params_dict[\"no_cov\"] = True\n",
    "    params_dict[\"impute\"] = False\n",
    "    params_dict[\"verbose\"] = 0 #from 0 to 3 (highest)\n",
    "\n",
    "    params_dict[\"T_val\"] = 150\n",
    "    params_dict[\"max_val_samples\"] = 3\n",
    "\n",
    "\n",
    "\n",
    "    info, val_metric_prev, test_loglik, test_auc, test_mse = train_gruode (\n",
    "                                                                            simulation_name = simulation_name,\n",
    "                                                                            params_dict = params_dict,\n",
    "                                                                            device = device,\n",
    "                                                                            train_idx = train_idx,\n",
    "                                                                            val_idx = val_idx,\n",
    "                                                                            test_idx = test_idx,\n",
    "                                                                            epoch_max=10\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9daf360dec88400b8df0b209562a48c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
